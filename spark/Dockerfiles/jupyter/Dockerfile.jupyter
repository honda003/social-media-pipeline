FROM apache/spark:3.5.0

# Switch to root
USER root

# Install Python, pip, and Jupyter dependencies
RUN apt-get update && \
    apt-get install -y python3 python3-pip python3-venv wget && \
    pip3 install --no-cache-dir notebook==7.1.3 ipywidgets findspark traitlets delta-spark==2.4.0 pyspark==3.5.0 && \
    apt-get clean && rm -rf /var/lib/apt/lists/*

# Download required JARs for MinIO (S3a) and Postgres
RUN wget https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.6/hadoop-aws-3.3.6.jar -P /opt/spark/jars/ && \
    wget https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.520/aws-java-sdk-bundle-1.12.520.jar -P /opt/spark/jars/ && \
    wget https://repo1.maven.org/maven2/org/postgresql/postgresql/42.6.0/postgresql-42.6.0.jar -P /opt/spark/jars/

# Create spark user if not exists
RUN id -u spark >/dev/null 2>&1 || useradd -m -u 1000 spark

# Create directories and set ownership
RUN mkdir -p /opt/notebooks /opt/spark/tmp /opt/spark/conf && \
    chown -R spark:spark /opt/notebooks

# Switch to spark user
USER spark
WORKDIR /opt/notebooks

# Set Jupyter directories
ENV JUPYTER_RUNTIME_DIR=/opt/notebooks/.jupyter/runtime
ENV JUPYTER_DATA_DIR=/opt/notebooks/.jupyter/data
ENV JUPYTER_CONFIG_DIR=/opt/notebooks/.jupyter/config

RUN mkdir -p $JUPYTER_RUNTIME_DIR $JUPYTER_DATA_DIR $JUPYTER_CONFIG_DIR && \
    chown -R spark:spark /opt/notebooks/.jupyter

# Spark & Python settings
ENV PYSPARK_PYTHON=python3
ENV PYSPARK_DRIVER_PYTHON=python3
ENV SPARK_HOME=/opt/spark
ENV PATH="$SPARK_HOME/bin:$SPARK_HOME/sbin:$PATH"

# Start Jupyter Notebook
CMD ["jupyter", "notebook", "--ip=0.0.0.0", "--port=8888", \
     "--NotebookApp.notebook_dir=/opt/notebooks", \
     "--NotebookApp.token=", "--NotebookApp.password=", \
     "--NotebookApp.allow_origin=*", \
     "--NotebookApp.disable_check_xsrf=True"]